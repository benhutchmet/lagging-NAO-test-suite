{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions for NAO matching ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import local modules\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Importing third party modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules\n",
    "sys.path.append('/home/users/benhutch/lagging-NAO-test-suite/alternate_lag_suite')\n",
    "\n",
    "# Import alt lag functions\n",
    "import alternate_lag_functions as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the NAO function\n",
    "paths = funcs.calculate_nao_index(season=\"ONDJFM\",\n",
    "                            forecast_range=\"2-9\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function for preprocessing the model data\n",
    "def preprocess(ds: xr.Dataset,\n",
    "               forecast_range: str,\n",
    "               filenames: list,\n",
    "               lag: int,):\n",
    "    \"\"\"\n",
    "    Preprocess the model data using xarray\n",
    "    \"\"\"\n",
    "\n",
    "    # /gws/nopw/j04/canari/users/benhutch/skill-maps-processed-data/psl/BCC-CSM2-MR/global/2-9/ONDJFM/outputs/all-years-ONDJFM-global-psl_Amon_BCC-CSM2-MR_dcppA-hindcast_s1961-r1i1p1f1_gn_196101-197012_years_2-9_start_1961_end_2014_anoms.nc\n",
    "\n",
    "    # Expand the dimensions of the dataset\n",
    "    ds = ds.expand_dims('ensemble_member')\n",
    "\n",
    "    # Set up the params for the ensemble member\n",
    "    # Split the filename by the final /\n",
    "    filenames_split = [file.split(\"/\")[-1] for file in filenames]\n",
    "\n",
    "    # Split the filename by the _\n",
    "    model_name = [file.split(\"_\")[2] for file in filenames_split]\n",
    "\n",
    "    # Split the filename by the _\n",
    "    variant_label = [file.split(\"_\")[4].split(\"-\")[1] for file in filenames_split]\n",
    "\n",
    "    # Extract the unique model names\n",
    "    model_name = np.unique(model_name)[0]\n",
    "\n",
    "    # Extract the unique variant labels\n",
    "    variant_label = np.unique(variant_label)[0]\n",
    "\n",
    "    # Set the ensemble member\n",
    "    ds['ensemble_member'] = [f\"{model_name}_{variant_label}_lag_{lag}\"]\n",
    "\n",
    "    # Extract the years from the data\n",
    "    years = ds.time.dt.year.values\n",
    "\n",
    "    # Find the unique years\n",
    "    unique_years = np.unique(years)\n",
    "\n",
    "    # If forecast range contains a hyphen\n",
    "    if \"-\" in forecast_range:\n",
    "        start_year_idx = int(forecast_range.split(\"-\")[0])\n",
    "        end_year_idx = int(forecast_range.split(\"-\")[1])\n",
    "    else:\n",
    "        start_year_idx = int(forecast_range)\n",
    "        end_year_idx = int(forecast_range)\n",
    "\n",
    "    # Extract the first year\n",
    "    first_year = int(unique_years[start_year_idx - 2])\n",
    "\n",
    "    # Extract the last year\n",
    "    last_year = int(unique_years[end_year_idx - 2])\n",
    "\n",
    "    # If the forecast range is years 2-9\n",
    "    if forecast_range == \"2-9\":\n",
    "        # Form the strings for the start and end dates\n",
    "        start_date = f\"{first_year}-01-01\" ; end_date = f\"{last_year + 1}-01-01\"\n",
    "    elif forecast_range == \"2-5\":\n",
    "        # Form the strings for the start and end dates depending on the lag\n",
    "        if lag == 0:\n",
    "            start_date = f\"{first_year}-01-01\" ; end_date = f\"{first_year + 1}-01-01\"\n",
    "        else:\n",
    "            start_date = f\"{first_year + lag}-01-01\" ; end_date = f\"{last_year + lag + 1}-01-01\"\n",
    "    else:\n",
    "        # Assertion error, forecast range not recognised\n",
    "        assert False, \"Forecast range not recognised\"\n",
    "\n",
    "    # Find the centre of the period between start and end date\n",
    "    mid_date = pd.to_datetime(start_date) + (pd.to_datetime(end_date) - pd.to_datetime(start_date)) / 2\n",
    "\n",
    "    # Take the mean over the time dimension\n",
    "    ds = ds.sel(time=slice(start_date, end_date)).mean(dim='time')\n",
    "\n",
    "    # If the lag is 0\n",
    "    if lag == 0:\n",
    "        # Set the time to the mid date\n",
    "        ds['time'] = mid_date\n",
    "    else:\n",
    "        # Set the time to the mid date\n",
    "        ds['time'] = mid_date + pd.DateOffset(years=lag)\n",
    "\n",
    "    # Return the dataset\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the paths to the first 8\n",
    "paths = paths[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcc_test = []\n",
    "\n",
    "# Loop over the paths\n",
    "for path in tqdm(paths):\n",
    "\n",
    "    # Loop over the lags\n",
    "    for k in range(0, 4):\n",
    "        # print(f\"Processing lag index {k}\")\n",
    "\n",
    "        # Load the data\n",
    "        ds = xr.open_mfdataset(path,\n",
    "                            preprocess=lambda ds: preprocess(ds, forecast_range=\"2-9\",\n",
    "                                                                filenames=path,\n",
    "                                                                lag=k),\n",
    "                            combine='nested',\n",
    "                            concat_dim='time',\n",
    "                            join='override',\n",
    "                            coords='minimal',\n",
    "                            engine='netcdf4',\n",
    "                            parallel=True,)\n",
    "    \n",
    "        # Append the data to the list\n",
    "        bcc_test.append(ds)\n",
    "\n",
    "# Concatenate the data\n",
    "bcc_test = xr.concat(bcc_test, dim='ensemble_member')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcc_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
