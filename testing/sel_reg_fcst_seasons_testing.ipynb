{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New way of regridding step ###\n",
    "\n",
    "Old way doesn't consistently work. Doing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import local modules\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Import third-party modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions from the local modules\n",
    "from sel_reg_fcst_seasons_functions import *\n",
    "\n",
    "# Import the dictionary\n",
    "sys.path.append('/home/users/benhutch/lagging-NAO-test-suite/')\n",
    "                \n",
    "# Import the dictionary\n",
    "import dictionaries as dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the load data function\n",
    "# First set up the params\n",
    "variable = \"pr\"\n",
    "model = \"EC-Earth3\"\n",
    "experiment = \"dcppA-hindcast\"\n",
    "start_year = 1961\n",
    "end_year = 2014\n",
    "season = \"AYULGS\"\n",
    "region = \"global\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up the list of variables\n",
    "# variables = [\"pr\", \"tas\", \"psl\", \"rsds\", \"sfcWind\"]\n",
    "\n",
    "# # Set up the model \n",
    "# model = \"CanESM5\"\n",
    "\n",
    "# # Find the files\n",
    "# csv_path = \"/home/users/benhutch/lagging-NAO-test-suite/data_paths/paths_to_file_src.csv\"\n",
    "\n",
    "# # Load the data\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# # Loop over the variables\n",
    "# for var in variables:\n",
    "#     # Find the corresponding path\n",
    "#     path = df[(df.variable == var) & (df.model == model) & (df.experiment == experiment)].path.values[0]\n",
    "\n",
    "#     # Assert that this path exists\n",
    "#     assert os.path.exists(path), f\"Path {path} does not exist\"\n",
    "\n",
    "#     # Find the model path root\n",
    "#     model_path_root = path.split(\"/\")[1]\n",
    "\n",
    "#     # Set up the valid r numbers\n",
    "#     valid_r_numbers = [re.compile(f\"r{i}i.*p.*f.*\") for i in range(1, 21)]\n",
    "\n",
    "#     # If the model path is \"gws\"\n",
    "#     if model_path_root == \"gws\":\n",
    "#         # Find the model files\n",
    "#         model_files = os.listdir(path)\n",
    "\n",
    "#         # Find the files which don't contain the valid r numbers\n",
    "#         model_files_invalid = [file for file in model_files if not any(r.match(file) for r in valid_r_numbers)]\n",
    "\n",
    "#         # Set up a new folder for these members\n",
    "#         new_folder = os.path.join(path, \"additional_members\")\n",
    "\n",
    "#         # If this folder doesn't exist, create it\n",
    "#         if not os.path.exists(new_folder):\n",
    "#             os.mkdir(new_folder)\n",
    "\n",
    "#         # Move the files to this folder\n",
    "#         for file in model_files_invalid:\n",
    "#             os.rename(os.path.join(path, file), os.path.join(new_folder, file))\n",
    "\n",
    "#         # Verify that only the valid files are left\n",
    "#         for file in os.listdir(path):\n",
    "#             assert any(r.match(file) for r in valid_r_numbers), f\"File {file} is not valid\"\n",
    "\n",
    "#     # If the model path is \"badc\"\n",
    "#     elif model_path_root == \"badc\":\n",
    "#         # Find the model files\n",
    "#         model_files = os.listdir(path)\n",
    "\n",
    "#         # Find the unique members\n",
    "#         model_files_split = [file.split(\"/\")[-1] for file in model_files]\n",
    "\n",
    "#         print(model_files_split)\n",
    "\n",
    "#         # From the model_files_split, remove the string which don't contain \"-\"\n",
    "#         model_files_split = [file for file in model_files_split if \"-\" in file]\n",
    "\n",
    "#         # Split the model_files_split by \"-\"\n",
    "#         model_files_split = [file.split(\"-\")[1] for file in model_files_split]\n",
    "\n",
    "#         # Find the unique members\n",
    "#         unique_members = list(set(model_files_split))\n",
    "\n",
    "#         # Assert that only the valid members are present\n",
    "#         assert len(unique_members) == 20, f\"Members are not unique: {unique_members}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique members are:  ['r3i1p1f1', 'r5i1p1f1', 'r2i1p1f1', 'r6i1p1f1', 'r7i1p1f1', 'r8i1p1f1', 'r1i1p1f1', 'r4i1p1f1']\n",
      "The length of the unique members is:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/54 [00:00<00:01, 26.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:02<00:00, 25.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique members are:  ['r3i1p1f1', 'r5i1p1f1', 'r10i1p1f1', 'r2i1p1f1', 'r6i1p1f1', 'r7i1p1f1', 'r8i1p1f1', 'r1i1p1f1', 'r4i1p1f1', 'r9i1p1f1']\n",
      "The length of the unique members is:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:03<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique members are:  ['r15i1p2f1', 'r13i1p2f1', 'r7i1p2f1', 'r10i1p2f1', 'r2i1p2f1', 'r16i1p2f1', 'r12i1p2f1', 'r14i1p2f1', 'r11i1p2f1', 'r20i1p2f1', 'r3i1p2f1', 'r8i1p2f1', 'r6i1p2f1', 'r17i1p2f1', 'r18i1p2f1', 'r5i1p2f1', 'r9i1p2f1', 'r1i1p2f1', 'r4i1p2f1', 'r19i1p2f1']\n",
      "The length of the unique members is:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:16<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique members are:  ['r3i1p1f1', 'r5i1p1f1', 'r10i1p1f1', 'r2i1p1f1', 'r6i1p1f1', 'r7i1p1f1', 'r8i1p1f1', 'r1i1p1f1', 'r4i1p1f1', 'r9i1p1f1']\n",
      "The length of the unique members is:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 24/54 [00:01<00:02, 13.61it/s]"
     ]
    }
   ],
   "source": [
    "# Loop over the models\n",
    "for model in dicts.pr_models:\n",
    "    # First check that the files don't already exist\n",
    "    df = check_regrid_files_exist(variable=variable,\n",
    "                                model=model,\n",
    "                                season=season,\n",
    "                                experiment=experiment,\n",
    "                                region=region,\n",
    "                                start_year=start_year,\n",
    "                                end_year=end_year,\n",
    "                                )\n",
    "    \n",
    "    # Assert that all of the file_exist are True\n",
    "    assert all(df[\"file exists\"]), f\"Files already exist for {model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the functions\n",
    "file_paths = load_model_data(variable=variable,\n",
    "                             model=model,\n",
    "                             experiment=experiment,\n",
    "                             start_year=start_year,\n",
    "                             end_year=end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the functoin for processing the intermediate files\n",
    "int_file_paths = sel_season_shift(file_paths=file_paths,\n",
    "                                  year = 1962,\n",
    "                                  season=\"ONDJFM\",\n",
    "                                  variable=variable,\n",
    "                                  model=model,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test regridding these intermediate files\n",
    "regrid_file_paths = regrid_int_files(int_file_paths=int_file_paths,\n",
    "                                     variable=variable,\n",
    "                                     model=model,\n",
    "                                     season=\"ONDJFM\",\n",
    "                                     region=\"global\",\n",
    "                                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
